------------------------------------- Calculate Flops Results -------------------------------------
Notations:
number of parameters (Params), number of multiply-accumulate operations(MACs),
number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),
fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),
default model backpropagation takes 2.00 times as much computation as forward propagation.

Total Training Params:                                                  2.22 M  
fwd MACs:                                                               2.39 GMACs
fwd FLOPs:                                                              4.85 GFLOPS
fwd+bwd MACs:                                                           7.17 GMACs
fwd+bwd FLOPs:                                                          14.56 GFLOPS

-------------------------------- Detailed Calculated FLOPs Results --------------------------------
Each module caculated is listed after its name in the following order: 
params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs

Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). 
 They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.
2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.

MobileNetV2(
  2.22 M = 100% Params, 2.39 GMACs = 100% MACs, 4.85 GFLOPS = 49.23% FLOPs
  (features): Sequential(
    1.91 M = 86.35% Params, 1.46 GMACs = 61.21% MACs, 2.99 GFLOPS = 30.13% FLOPs
    (0): Conv2dNormActivation(
      928 = 0.04% Params, 55.74 MMACs = 2.33% MACs, 115.61 MFLOPS = 1.15% FLOPs
      (0): Conv2d(864 = 0.04% Params, 55.74 MMACs = 2.33% MACs, 111.48 MFLOPS = 1.15% FLOPs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64 = 0% Params, 0 MACs = 0% MACs, 4.13 MFLOPS = 0% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
    )
    (1): InvertedResidual(
      896 = 0.04% Params, 51.61 MMACs = 2.16% MACs, 109.41 MFLOPS = 1.06% FLOPs
      (conv): Sequential(
        896 = 0.04% Params, 51.61 MMACs = 2.16% MACs, 109.41 MFLOPS = 1.06% FLOPs
        (0): Conv2dNormActivation(
          352 = 0.02% Params, 18.58 MMACs = 0.78% MACs, 41.29 MFLOPS = 0.38% FLOPs
          (0): Conv2d(288 = 0.01% Params, 18.58 MMACs = 0.78% MACs, 37.16 MFLOPS = 0.38% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (1): BatchNorm2d(64 = 0% Params, 0 MACs = 0% MACs, 4.13 MFLOPS = 0% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2d(512 = 0.02% Params, 33.03 MMACs = 1.38% MACs, 66.06 MFLOPS = 0.68% FLOPs, 32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (2): BatchNorm2d(32 = 0% Params, 0 MACs = 0% MACs, 2.06 MFLOPS = 0% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): InvertedResidual(
      5.14 K = 0.23% Params, 150.18 MMACs = 6.28% MACs, 316.62 MFLOPS = 3.09% FLOPs
      (conv): Sequential(
        5.14 K = 0.23% Params, 150.18 MMACs = 6.28% MACs, 316.62 MFLOPS = 3.09% FLOPs
        (0): Conv2dNormActivation(
          1.73 K = 0.08% Params, 99.09 MMACs = 4.15% MACs, 210.57 MFLOPS = 2.04% FLOPs
          (0): Conv2d(1.54 K = 0.07% Params, 99.09 MMACs = 4.15% MACs, 198.18 MFLOPS = 2.04% FLOPs, 16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192 = 0.01% Params, 0 MACs = 0% MACs, 12.39 MFLOPS = 0% FLOPs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          1.06 K = 0.05% Params, 13.93 MMACs = 0.58% MACs, 30.97 MFLOPS = 0.29% FLOPs
          (0): Conv2d(864 = 0.04% Params, 13.93 MMACs = 0.58% MACs, 27.87 MFLOPS = 0.29% FLOPs, 96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
          (1): BatchNorm2d(192 = 0.01% Params, 0 MACs = 0% MACs, 3.1 MFLOPS = 0% FLOPs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(2.3 K = 0.1% Params, 37.16 MMACs = 1.55% MACs, 74.32 MFLOPS = 0.77% FLOPs, 96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(48 = 0% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): InvertedResidual(
      8.83 K = 0.4% Params, 132.38 MMACs = 5.54% MACs, 274.82 MFLOPS = 2.73% FLOPs
      (conv): Sequential(
        8.83 K = 0.4% Params, 132.38 MMACs = 5.54% MACs, 274.82 MFLOPS = 2.73% FLOPs
        (0): Conv2dNormActivation(
          3.74 K = 0.17% Params, 55.74 MMACs = 2.33% MACs, 116.12 MFLOPS = 1.15% FLOPs
          (0): Conv2d(3.46 K = 0.16% Params, 55.74 MMACs = 2.33% MACs, 111.48 MFLOPS = 1.15% FLOPs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(288 = 0.01% Params, 0 MACs = 0% MACs, 4.64 MFLOPS = 0% FLOPs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          1.58 K = 0.07% Params, 20.9 MMACs = 0.87% MACs, 46.45 MFLOPS = 0.43% FLOPs
          (0): Conv2d(1.3 K = 0.06% Params, 20.9 MMACs = 0.87% MACs, 41.8 MFLOPS = 0.43% FLOPs, 144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
          (1): BatchNorm2d(288 = 0.01% Params, 0 MACs = 0% MACs, 4.64 MFLOPS = 0% FLOPs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(3.46 K = 0.16% Params, 55.74 MMACs = 2.33% MACs, 111.48 MFLOPS = 1.15% FLOPs, 144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(48 = 0% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): InvertedResidual(
      10 K = 0.45% Params, 79.54 MMACs = 3.33% MACs, 165.15 MFLOPS = 1.64% FLOPs
      (conv): Sequential(
        10 K = 0.45% Params, 79.54 MMACs = 3.33% MACs, 165.15 MFLOPS = 1.64% FLOPs
        (0): Conv2dNormActivation(
          3.74 K = 0.17% Params, 55.74 MMACs = 2.33% MACs, 116.12 MFLOPS = 1.15% FLOPs
          (0): Conv2d(3.46 K = 0.16% Params, 55.74 MMACs = 2.33% MACs, 111.48 MFLOPS = 1.15% FLOPs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(288 = 0.01% Params, 0 MACs = 0% MACs, 4.64 MFLOPS = 0% FLOPs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          1.58 K = 0.07% Params, 5.23 MMACs = 0.22% MACs, 11.61 MFLOPS = 0.11% FLOPs
          (0): Conv2d(1.3 K = 0.06% Params, 5.23 MMACs = 0.22% MACs, 10.45 MFLOPS = 0.11% FLOPs, 144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
          (1): BatchNorm2d(288 = 0.01% Params, 0 MACs = 0% MACs, 1.16 MFLOPS = 0% FLOPs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(4.61 K = 0.21% Params, 18.58 MMACs = 0.78% MACs, 37.16 MFLOPS = 0.38% FLOPs, 144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64 = 0% Params, 0 MACs = 0% MACs, 258.05 KFLOPS = 0% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): InvertedResidual(
      14.85 K = 0.67% Params, 56.51 MMACs = 2.36% MACs, 116.38 MFLOPS = 1.16% FLOPs
      (conv): Sequential(
        14.85 K = 0.67% Params, 56.51 MMACs = 2.36% MACs, 116.38 MFLOPS = 1.16% FLOPs
        (0): Conv2dNormActivation(
          6.53 K = 0.29% Params, 24.77 MMACs = 1.04% MACs, 51.09 MFLOPS = 0.51% FLOPs
          (0): Conv2d(6.14 K = 0.28% Params, 24.77 MMACs = 1.04% MACs, 49.55 MFLOPS = 0.51% FLOPs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384 = 0.02% Params, 0 MACs = 0% MACs, 1.55 MFLOPS = 0% FLOPs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          2.11 K = 0.1% Params, 6.97 MMACs = 0.29% MACs, 15.48 MFLOPS = 0.14% FLOPs
          (0): Conv2d(1.73 K = 0.08% Params, 6.97 MMACs = 0.29% MACs, 13.93 MFLOPS = 0.14% FLOPs, 192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
          (1): BatchNorm2d(384 = 0.02% Params, 0 MACs = 0% MACs, 1.55 MFLOPS = 0% FLOPs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(6.14 K = 0.28% Params, 24.77 MMACs = 1.04% MACs, 49.55 MFLOPS = 0.51% FLOPs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64 = 0% Params, 0 MACs = 0% MACs, 258.05 KFLOPS = 0% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): InvertedResidual(
      14.85 K = 0.67% Params, 56.51 MMACs = 2.36% MACs, 116.38 MFLOPS = 1.16% FLOPs
      (conv): Sequential(
        14.85 K = 0.67% Params, 56.51 MMACs = 2.36% MACs, 116.38 MFLOPS = 1.16% FLOPs
        (0): Conv2dNormActivation(
          6.53 K = 0.29% Params, 24.77 MMACs = 1.04% MACs, 51.09 MFLOPS = 0.51% FLOPs
          (0): Conv2d(6.14 K = 0.28% Params, 24.77 MMACs = 1.04% MACs, 49.55 MFLOPS = 0.51% FLOPs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384 = 0.02% Params, 0 MACs = 0% MACs, 1.55 MFLOPS = 0% FLOPs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          2.11 K = 0.1% Params, 6.97 MMACs = 0.29% MACs, 15.48 MFLOPS = 0.14% FLOPs
          (0): Conv2d(1.73 K = 0.08% Params, 6.97 MMACs = 0.29% MACs, 13.93 MFLOPS = 0.14% FLOPs, 192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
          (1): BatchNorm2d(384 = 0.02% Params, 0 MACs = 0% MACs, 1.55 MFLOPS = 0% FLOPs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(6.14 K = 0.28% Params, 24.77 MMACs = 1.04% MACs, 49.55 MFLOPS = 0.51% FLOPs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64 = 0% Params, 0 MACs = 0% MACs, 258.05 KFLOPS = 0% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): InvertedResidual(
      21.06 K = 0.95% Params, 38.9 MMACs = 1.63% MACs, 79.87 MFLOPS = 0.8% FLOPs
      (conv): Sequential(
        21.06 K = 0.95% Params, 38.9 MMACs = 1.63% MACs, 79.87 MFLOPS = 0.8% FLOPs
        (0): Conv2dNormActivation(
          6.53 K = 0.29% Params, 24.77 MMACs = 1.04% MACs, 51.09 MFLOPS = 0.51% FLOPs
          (0): Conv2d(6.14 K = 0.28% Params, 24.77 MMACs = 1.04% MACs, 49.55 MFLOPS = 0.51% FLOPs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384 = 0.02% Params, 0 MACs = 0% MACs, 1.55 MFLOPS = 0% FLOPs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          2.11 K = 0.1% Params, 1.74 MMACs = 0.07% MACs, 3.87 MFLOPS = 0.04% FLOPs
          (0): Conv2d(1.73 K = 0.08% Params, 1.74 MMACs = 0.07% MACs, 3.48 MFLOPS = 0.04% FLOPs, 192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
          (1): BatchNorm2d(384 = 0.02% Params, 0 MACs = 0% MACs, 387.07 KFLOPS = 0% FLOPs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(12.29 K = 0.55% Params, 12.39 MMACs = 0.52% MACs, 24.77 MFLOPS = 0.26% FLOPs, 192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(128 = 0.01% Params, 0 MACs = 0% MACs, 129.02 KFLOPS = 0% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (8): InvertedResidual(
      54.27 K = 2.45% Params, 53.03 MMACs = 2.22% MACs, 107.74 MFLOPS = 1.09% FLOPs
      (conv): Sequential(
        54.27 K = 2.45% Params, 53.03 MMACs = 2.22% MACs, 107.74 MFLOPS = 1.09% FLOPs
        (0): Conv2dNormActivation(
          25.34 K = 1.14% Params, 24.77 MMACs = 1.04% MACs, 50.32 MFLOPS = 0.51% FLOPs
          (0): Conv2d(24.58 K = 1.11% Params, 24.77 MMACs = 1.04% MACs, 49.55 MFLOPS = 0.51% FLOPs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          4.22 K = 0.19% Params, 3.48 MMACs = 0.15% MACs, 7.74 MFLOPS = 0.07% FLOPs
          (0): Conv2d(3.46 K = 0.16% Params, 3.48 MMACs = 0.15% MACs, 6.97 MFLOPS = 0.07% FLOPs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(24.58 K = 1.11% Params, 24.77 MMACs = 1.04% MACs, 49.55 MFLOPS = 0.51% FLOPs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(128 = 0.01% Params, 0 MACs = 0% MACs, 129.02 KFLOPS = 0% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (9): InvertedResidual(
      54.27 K = 2.45% Params, 53.03 MMACs = 2.22% MACs, 107.74 MFLOPS = 1.09% FLOPs
      (conv): Sequential(
        54.27 K = 2.45% Params, 53.03 MMACs = 2.22% MACs, 107.74 MFLOPS = 1.09% FLOPs
        (0): Conv2dNormActivation(
          25.34 K = 1.14% Params, 24.77 MMACs = 1.04% MACs, 50.32 MFLOPS = 0.51% FLOPs
          (0): Conv2d(24.58 K = 1.11% Params, 24.77 MMACs = 1.04% MACs, 49.55 MFLOPS = 0.51% FLOPs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          4.22 K = 0.19% Params, 3.48 MMACs = 0.15% MACs, 7.74 MFLOPS = 0.07% FLOPs
          (0): Conv2d(3.46 K = 0.16% Params, 3.48 MMACs = 0.15% MACs, 6.97 MFLOPS = 0.07% FLOPs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(24.58 K = 1.11% Params, 24.77 MMACs = 1.04% MACs, 49.55 MFLOPS = 0.51% FLOPs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(128 = 0.01% Params, 0 MACs = 0% MACs, 129.02 KFLOPS = 0% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (10): InvertedResidual(
      54.27 K = 2.45% Params, 53.03 MMACs = 2.22% MACs, 107.74 MFLOPS = 1.09% FLOPs
      (conv): Sequential(
        54.27 K = 2.45% Params, 53.03 MMACs = 2.22% MACs, 107.74 MFLOPS = 1.09% FLOPs
        (0): Conv2dNormActivation(
          25.34 K = 1.14% Params, 24.77 MMACs = 1.04% MACs, 50.32 MFLOPS = 0.51% FLOPs
          (0): Conv2d(24.58 K = 1.11% Params, 24.77 MMACs = 1.04% MACs, 49.55 MFLOPS = 0.51% FLOPs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          4.22 K = 0.19% Params, 3.48 MMACs = 0.15% MACs, 7.74 MFLOPS = 0.07% FLOPs
          (0): Conv2d(3.46 K = 0.16% Params, 3.48 MMACs = 0.15% MACs, 6.97 MFLOPS = 0.07% FLOPs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(24.58 K = 1.11% Params, 24.77 MMACs = 1.04% MACs, 49.55 MFLOPS = 0.51% FLOPs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(128 = 0.01% Params, 0 MACs = 0% MACs, 129.02 KFLOPS = 0% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (11): InvertedResidual(
      66.62 K = 3% Params, 65.42 MMACs = 2.74% MACs, 132.57 MFLOPS = 1.35% FLOPs
      (conv): Sequential(
        66.62 K = 3% Params, 65.42 MMACs = 2.74% MACs, 132.57 MFLOPS = 1.35% FLOPs
        (0): Conv2dNormActivation(
          25.34 K = 1.14% Params, 24.77 MMACs = 1.04% MACs, 50.32 MFLOPS = 0.51% FLOPs
          (0): Conv2d(24.58 K = 1.11% Params, 24.77 MMACs = 1.04% MACs, 49.55 MFLOPS = 0.51% FLOPs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          4.22 K = 0.19% Params, 3.48 MMACs = 0.15% MACs, 7.74 MFLOPS = 0.07% FLOPs
          (0): Conv2d(3.46 K = 0.16% Params, 3.48 MMACs = 0.15% MACs, 6.97 MFLOPS = 0.07% FLOPs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(36.86 K = 1.66% Params, 37.16 MMACs = 1.55% MACs, 74.32 MFLOPS = 0.77% FLOPs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(192 = 0.01% Params, 0 MACs = 0% MACs, 193.54 KFLOPS = 0% FLOPs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (12): InvertedResidual(
      118.27 K = 5.33% Params, 116.7 MMACs = 4.88% MACs, 235.92 MFLOPS = 2.4% FLOPs
      (conv): Sequential(
        118.27 K = 5.33% Params, 116.7 MMACs = 4.88% MACs, 235.92 MFLOPS = 2.4% FLOPs
        (0): Conv2dNormActivation(
          56.45 K = 2.55% Params, 55.74 MMACs = 2.33% MACs, 112.64 MFLOPS = 1.15% FLOPs
          (0): Conv2d(55.3 K = 2.49% Params, 55.74 MMACs = 2.33% MACs, 111.48 MFLOPS = 1.15% FLOPs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1.15 K = 0.05% Params, 0 MACs = 0% MACs, 1.16 MFLOPS = 0% FLOPs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          6.34 K = 0.29% Params, 5.23 MMACs = 0.22% MACs, 11.61 MFLOPS = 0.11% FLOPs
          (0): Conv2d(5.18 K = 0.23% Params, 5.23 MMACs = 0.22% MACs, 10.45 MFLOPS = 0.11% FLOPs, 576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
          (1): BatchNorm2d(1.15 K = 0.05% Params, 0 MACs = 0% MACs, 1.16 MFLOPS = 0% FLOPs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(55.3 K = 2.49% Params, 55.74 MMACs = 2.33% MACs, 111.48 MFLOPS = 1.15% FLOPs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(192 = 0.01% Params, 0 MACs = 0% MACs, 193.54 KFLOPS = 0% FLOPs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): InvertedResidual(
      118.27 K = 5.33% Params, 116.7 MMACs = 4.88% MACs, 235.92 MFLOPS = 2.4% FLOPs
      (conv): Sequential(
        118.27 K = 5.33% Params, 116.7 MMACs = 4.88% MACs, 235.92 MFLOPS = 2.4% FLOPs
        (0): Conv2dNormActivation(
          56.45 K = 2.55% Params, 55.74 MMACs = 2.33% MACs, 112.64 MFLOPS = 1.15% FLOPs
          (0): Conv2d(55.3 K = 2.49% Params, 55.74 MMACs = 2.33% MACs, 111.48 MFLOPS = 1.15% FLOPs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1.15 K = 0.05% Params, 0 MACs = 0% MACs, 1.16 MFLOPS = 0% FLOPs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          6.34 K = 0.29% Params, 5.23 MMACs = 0.22% MACs, 11.61 MFLOPS = 0.11% FLOPs
          (0): Conv2d(5.18 K = 0.23% Params, 5.23 MMACs = 0.22% MACs, 10.45 MFLOPS = 0.11% FLOPs, 576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
          (1): BatchNorm2d(1.15 K = 0.05% Params, 0 MACs = 0% MACs, 1.16 MFLOPS = 0% FLOPs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(55.3 K = 2.49% Params, 55.74 MMACs = 2.33% MACs, 111.48 MFLOPS = 1.15% FLOPs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(192 = 0.01% Params, 0 MACs = 0% MACs, 193.54 KFLOPS = 0% FLOPs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (14): InvertedResidual(
      155.26 K = 7% Params, 80.27 MMACs = 3.36% MACs, 162.07 MFLOPS = 1.65% FLOPs
      (conv): Sequential(
        155.26 K = 7% Params, 80.27 MMACs = 3.36% MACs, 162.07 MFLOPS = 1.65% FLOPs
        (0): Conv2dNormActivation(
          56.45 K = 2.55% Params, 55.74 MMACs = 2.33% MACs, 112.64 MFLOPS = 1.15% FLOPs
          (0): Conv2d(55.3 K = 2.49% Params, 55.74 MMACs = 2.33% MACs, 111.48 MFLOPS = 1.15% FLOPs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1.15 K = 0.05% Params, 0 MACs = 0% MACs, 1.16 MFLOPS = 0% FLOPs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          6.34 K = 0.29% Params, 1.31 MMACs = 0.05% MACs, 2.9 MFLOPS = 0.03% FLOPs
          (0): Conv2d(5.18 K = 0.23% Params, 1.31 MMACs = 0.05% MACs, 2.61 MFLOPS = 0.03% FLOPs, 576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)
          (1): BatchNorm2d(1.15 K = 0.05% Params, 0 MACs = 0% MACs, 290.3 KFLOPS = 0% FLOPs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(92.16 K = 4.16% Params, 23.22 MMACs = 0.97% MACs, 46.45 MFLOPS = 0.48% FLOPs, 576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(320 = 0.01% Params, 0 MACs = 0% MACs, 80.64 KFLOPS = 0% FLOPs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (15): InvertedResidual(
      320 K = 14.43% Params, 79.59 MMACs = 3.33% MACs, 160.23 MFLOPS = 1.64% FLOPs
      (conv): Sequential(
        320 K = 14.43% Params, 79.59 MMACs = 3.33% MACs, 160.23 MFLOPS = 1.64% FLOPs
        (0): Conv2dNormActivation(
          155.52 K = 7.01% Params, 38.71 MMACs = 1.62% MACs, 77.9 MFLOPS = 0.8% FLOPs
          (0): Conv2d(153.6 K = 6.93% Params, 38.71 MMACs = 1.62% MACs, 77.41 MFLOPS = 0.8% FLOPs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1.92 K = 0.09% Params, 0 MACs = 0% MACs, 483.84 KFLOPS = 0% FLOPs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          10.56 K = 0.48% Params, 2.18 MMACs = 0.09% MACs, 4.84 MFLOPS = 0.04% FLOPs
          (0): Conv2d(8.64 K = 0.39% Params, 2.18 MMACs = 0.09% MACs, 4.35 MFLOPS = 0.04% FLOPs, 960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
          (1): BatchNorm2d(1.92 K = 0.09% Params, 0 MACs = 0% MACs, 483.84 KFLOPS = 0% FLOPs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(153.6 K = 6.93% Params, 38.71 MMACs = 1.62% MACs, 77.41 MFLOPS = 0.8% FLOPs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(320 = 0.01% Params, 0 MACs = 0% MACs, 80.64 KFLOPS = 0% FLOPs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (16): InvertedResidual(
      320 K = 14.43% Params, 79.59 MMACs = 3.33% MACs, 160.23 MFLOPS = 1.64% FLOPs
      (conv): Sequential(
        320 K = 14.43% Params, 79.59 MMACs = 3.33% MACs, 160.23 MFLOPS = 1.64% FLOPs
        (0): Conv2dNormActivation(
          155.52 K = 7.01% Params, 38.71 MMACs = 1.62% MACs, 77.9 MFLOPS = 0.8% FLOPs
          (0): Conv2d(153.6 K = 6.93% Params, 38.71 MMACs = 1.62% MACs, 77.41 MFLOPS = 0.8% FLOPs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1.92 K = 0.09% Params, 0 MACs = 0% MACs, 483.84 KFLOPS = 0% FLOPs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          10.56 K = 0.48% Params, 2.18 MMACs = 0.09% MACs, 4.84 MFLOPS = 0.04% FLOPs
          (0): Conv2d(8.64 K = 0.39% Params, 2.18 MMACs = 0.09% MACs, 4.35 MFLOPS = 0.04% FLOPs, 960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
          (1): BatchNorm2d(1.92 K = 0.09% Params, 0 MACs = 0% MACs, 483.84 KFLOPS = 0% FLOPs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(153.6 K = 6.93% Params, 38.71 MMACs = 1.62% MACs, 77.41 MFLOPS = 0.8% FLOPs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(320 = 0.01% Params, 0 MACs = 0% MACs, 80.64 KFLOPS = 0% FLOPs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (17): InvertedResidual(
      473.92 K = 21.37% Params, 118.3 MMACs = 4.95% MACs, 237.73 MFLOPS = 2.44% FLOPs
      (conv): Sequential(
        473.92 K = 21.37% Params, 118.3 MMACs = 4.95% MACs, 237.73 MFLOPS = 2.44% FLOPs
        (0): Conv2dNormActivation(
          155.52 K = 7.01% Params, 38.71 MMACs = 1.62% MACs, 77.9 MFLOPS = 0.8% FLOPs
          (0): Conv2d(153.6 K = 6.93% Params, 38.71 MMACs = 1.62% MACs, 77.41 MFLOPS = 0.8% FLOPs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1.92 K = 0.09% Params, 0 MACs = 0% MACs, 483.84 KFLOPS = 0% FLOPs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          10.56 K = 0.48% Params, 2.18 MMACs = 0.09% MACs, 4.84 MFLOPS = 0.04% FLOPs
          (0): Conv2d(8.64 K = 0.39% Params, 2.18 MMACs = 0.09% MACs, 4.35 MFLOPS = 0.04% FLOPs, 960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
          (1): BatchNorm2d(1.92 K = 0.09% Params, 0 MACs = 0% MACs, 483.84 KFLOPS = 0% FLOPs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(307.2 K = 13.85% Params, 77.41 MMACs = 3.24% MACs, 154.83 MFLOPS = 1.59% FLOPs, 960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(640 = 0.03% Params, 0 MACs = 0% MACs, 161.28 KFLOPS = 0% FLOPs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (18): Conv2dNormActivation(
      103.04 K = 4.65% Params, 25.8 MMACs = 1.08% MACs, 51.77 MFLOPS = 0.53% FLOPs
      (0): Conv2d(102.4 K = 4.62% Params, 25.8 MMACs = 1.08% MACs, 51.61 MFLOPS = 0.53% FLOPs, 320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(640 = 0.03% Params, 0 MACs = 0% MACs, 161.28 KFLOPS = 0% FLOPs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
    )
  )
  (deconv_layers): Sequential(
    256.24 K = 11.56% Params, 180.63 MMACs = 7.56% MACs, 363.81 MFLOPS = 3.72% FLOPs
    (0): ConvTranspose2d(204.8 K = 9.24% Params, 51.61 MMACs = 2.16% MACs, 103.22 MFLOPS = 1.06% FLOPs, 320, 40, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(80 = 0% Params, 0 MACs = 0% MACs, 80.64 KFLOPS = 0% FLOPs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 40.32 KFLOPS = 0% FLOPs, inplace=True)
    (3): ConvTranspose2d(25.6 K = 1.15% Params, 25.8 MMACs = 1.08% MACs, 51.61 MFLOPS = 0.53% FLOPs, 40, 40, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(80 = 0% Params, 0 MACs = 0% MACs, 322.56 KFLOPS = 0% FLOPs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 161.28 KFLOPS = 0% FLOPs, inplace=True)
    (6): ConvTranspose2d(25.6 K = 1.15% Params, 103.22 MMACs = 4.32% MACs, 206.44 MFLOPS = 2.13% FLOPs, 40, 40, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(80 = 0% Params, 0 MACs = 0% MACs, 1.29 MFLOPS = 0% FLOPs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 645.12 KFLOPS = 0% FLOPs, inplace=True)
  )
  (hm): Sequential(
    23.17 K = 1.04% Params, 372.62 MMACs = 15.59% MACs, 747.32 MFLOPS = 7.68% FLOPs
    (0): Conv2d(23.1 K = 1.04% Params, 371.59 MMACs = 15.55% MACs, 744.21 MFLOPS = 7.65% FLOPs, 40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.03 MFLOPS = 0% FLOPs, inplace=True)
    (2): Conv2d(65 = 0% Params, 1.03 MMACs = 0.04% MACs, 2.08 MFLOPS = 0.02% FLOPs, 64, 1, kernel_size=(1, 1), stride=(1, 1))
  )
  (reg): Sequential(
    23.23 K = 1.05% Params, 373.65 MMACs = 15.64% MACs, 749.4 MFLOPS = 7.7% FLOPs
    (0): Conv2d(23.1 K = 1.04% Params, 371.59 MMACs = 15.55% MACs, 744.21 MFLOPS = 7.65% FLOPs, 40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.03 MFLOPS = 0% FLOPs, inplace=True)
    (2): Conv2d(130 = 0.01% Params, 2.06 MMACs = 0.09% MACs, 4.16 MFLOPS = 0.04% FLOPs, 64, 2, kernel_size=(1, 1), stride=(1, 1))
  )
)
---------------------------------------------------------------------------------------------------
flops  4.85 GFLOPS
params 2.22 M