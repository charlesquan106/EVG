------------------------------------- Calculate Flops Results -------------------------------------
Notations:
number of parameters (Params), number of multiply-accumulate operations(MACs),
number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),
fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),
default model backpropagation takes 2.00 times as much computation as forward propagation.

Total Training Params:                                                  2.24 M  
fwd MACs:                                                               2.94 GMACs
fwd FLOPs:                                                              5.97 GFLOPS
fwd+bwd MACs:                                                           8.83 GMACs
fwd+bwd FLOPs:                                                          17.9 GFLOPS

-------------------------------- Detailed Calculated FLOPs Results --------------------------------
Each module caculated is listed after its name in the following order: 
params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs

Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). 
 They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.
2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.

MobileNetV2(
  2.24 M = 100% Params, 2.94 GMACs = 100% MACs, 5.97 GFLOPS = 49.33% FLOPs
  (features): Sequential(
    1.91 M = 85.46% Params, 1.46 GMACs = 49.69% MACs, 2.99 GFLOPS = 24.51% FLOPs
    (0): Conv2dNormActivation(
      928 = 0.04% Params, 55.74 MMACs = 1.89% MACs, 115.61 MFLOPS = 0.93% FLOPs
      (0): Conv2d(864 = 0.04% Params, 55.74 MMACs = 1.89% MACs, 111.48 MFLOPS = 0.93% FLOPs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64 = 0% Params, 0 MACs = 0% MACs, 4.13 MFLOPS = 0% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
    )
    (1): InvertedResidual(
      896 = 0.04% Params, 51.61 MMACs = 1.75% MACs, 109.41 MFLOPS = 0.86% FLOPs
      (conv): Sequential(
        896 = 0.04% Params, 51.61 MMACs = 1.75% MACs, 109.41 MFLOPS = 0.86% FLOPs
        (0): Conv2dNormActivation(
          352 = 0.02% Params, 18.58 MMACs = 0.63% MACs, 41.29 MFLOPS = 0.31% FLOPs
          (0): Conv2d(288 = 0.01% Params, 18.58 MMACs = 0.63% MACs, 37.16 MFLOPS = 0.31% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (1): BatchNorm2d(64 = 0% Params, 0 MACs = 0% MACs, 4.13 MFLOPS = 0% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2d(512 = 0.02% Params, 33.03 MMACs = 1.12% MACs, 66.06 MFLOPS = 0.55% FLOPs, 32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (2): BatchNorm2d(32 = 0% Params, 0 MACs = 0% MACs, 2.06 MFLOPS = 0% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): InvertedResidual(
      5.14 K = 0.23% Params, 150.18 MMACs = 5.1% MACs, 316.62 MFLOPS = 2.52% FLOPs
      (conv): Sequential(
        5.14 K = 0.23% Params, 150.18 MMACs = 5.1% MACs, 316.62 MFLOPS = 2.52% FLOPs
        (0): Conv2dNormActivation(
          1.73 K = 0.08% Params, 99.09 MMACs = 3.37% MACs, 210.57 MFLOPS = 1.66% FLOPs
          (0): Conv2d(1.54 K = 0.07% Params, 99.09 MMACs = 3.37% MACs, 198.18 MFLOPS = 1.66% FLOPs, 16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192 = 0.01% Params, 0 MACs = 0% MACs, 12.39 MFLOPS = 0% FLOPs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          1.06 K = 0.05% Params, 13.93 MMACs = 0.47% MACs, 30.97 MFLOPS = 0.23% FLOPs
          (0): Conv2d(864 = 0.04% Params, 13.93 MMACs = 0.47% MACs, 27.87 MFLOPS = 0.23% FLOPs, 96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
          (1): BatchNorm2d(192 = 0.01% Params, 0 MACs = 0% MACs, 3.1 MFLOPS = 0% FLOPs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(2.3 K = 0.1% Params, 37.16 MMACs = 1.26% MACs, 74.32 MFLOPS = 0.62% FLOPs, 96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(48 = 0% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): InvertedResidual(
      8.83 K = 0.39% Params, 132.38 MMACs = 4.5% MACs, 274.82 MFLOPS = 2.22% FLOPs
      (conv): Sequential(
        8.83 K = 0.39% Params, 132.38 MMACs = 4.5% MACs, 274.82 MFLOPS = 2.22% FLOPs
        (0): Conv2dNormActivation(
          3.74 K = 0.17% Params, 55.74 MMACs = 1.89% MACs, 116.12 MFLOPS = 0.93% FLOPs
          (0): Conv2d(3.46 K = 0.15% Params, 55.74 MMACs = 1.89% MACs, 111.48 MFLOPS = 0.93% FLOPs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(288 = 0.01% Params, 0 MACs = 0% MACs, 4.64 MFLOPS = 0% FLOPs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          1.58 K = 0.07% Params, 20.9 MMACs = 0.71% MACs, 46.45 MFLOPS = 0.35% FLOPs
          (0): Conv2d(1.3 K = 0.06% Params, 20.9 MMACs = 0.71% MACs, 41.8 MFLOPS = 0.35% FLOPs, 144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
          (1): BatchNorm2d(288 = 0.01% Params, 0 MACs = 0% MACs, 4.64 MFLOPS = 0% FLOPs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(3.46 K = 0.15% Params, 55.74 MMACs = 1.89% MACs, 111.48 MFLOPS = 0.93% FLOPs, 144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(48 = 0% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): InvertedResidual(
      10 K = 0.45% Params, 79.54 MMACs = 2.7% MACs, 165.15 MFLOPS = 1.33% FLOPs
      (conv): Sequential(
        10 K = 0.45% Params, 79.54 MMACs = 2.7% MACs, 165.15 MFLOPS = 1.33% FLOPs
        (0): Conv2dNormActivation(
          3.74 K = 0.17% Params, 55.74 MMACs = 1.89% MACs, 116.12 MFLOPS = 0.93% FLOPs
          (0): Conv2d(3.46 K = 0.15% Params, 55.74 MMACs = 1.89% MACs, 111.48 MFLOPS = 0.93% FLOPs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(288 = 0.01% Params, 0 MACs = 0% MACs, 4.64 MFLOPS = 0% FLOPs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          1.58 K = 0.07% Params, 5.23 MMACs = 0.18% MACs, 11.61 MFLOPS = 0.09% FLOPs
          (0): Conv2d(1.3 K = 0.06% Params, 5.23 MMACs = 0.18% MACs, 10.45 MFLOPS = 0.09% FLOPs, 144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
          (1): BatchNorm2d(288 = 0.01% Params, 0 MACs = 0% MACs, 1.16 MFLOPS = 0% FLOPs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(4.61 K = 0.21% Params, 18.58 MMACs = 0.63% MACs, 37.16 MFLOPS = 0.31% FLOPs, 144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64 = 0% Params, 0 MACs = 0% MACs, 258.05 KFLOPS = 0% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): InvertedResidual(
      14.85 K = 0.66% Params, 56.51 MMACs = 1.92% MACs, 116.38 MFLOPS = 0.95% FLOPs
      (conv): Sequential(
        14.85 K = 0.66% Params, 56.51 MMACs = 1.92% MACs, 116.38 MFLOPS = 0.95% FLOPs
        (0): Conv2dNormActivation(
          6.53 K = 0.29% Params, 24.77 MMACs = 0.84% MACs, 51.09 MFLOPS = 0.42% FLOPs
          (0): Conv2d(6.14 K = 0.27% Params, 24.77 MMACs = 0.84% MACs, 49.55 MFLOPS = 0.42% FLOPs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384 = 0.02% Params, 0 MACs = 0% MACs, 1.55 MFLOPS = 0% FLOPs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          2.11 K = 0.09% Params, 6.97 MMACs = 0.24% MACs, 15.48 MFLOPS = 0.12% FLOPs
          (0): Conv2d(1.73 K = 0.08% Params, 6.97 MMACs = 0.24% MACs, 13.93 MFLOPS = 0.12% FLOPs, 192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
          (1): BatchNorm2d(384 = 0.02% Params, 0 MACs = 0% MACs, 1.55 MFLOPS = 0% FLOPs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(6.14 K = 0.27% Params, 24.77 MMACs = 0.84% MACs, 49.55 MFLOPS = 0.42% FLOPs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64 = 0% Params, 0 MACs = 0% MACs, 258.05 KFLOPS = 0% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): InvertedResidual(
      14.85 K = 0.66% Params, 56.51 MMACs = 1.92% MACs, 116.38 MFLOPS = 0.95% FLOPs
      (conv): Sequential(
        14.85 K = 0.66% Params, 56.51 MMACs = 1.92% MACs, 116.38 MFLOPS = 0.95% FLOPs
        (0): Conv2dNormActivation(
          6.53 K = 0.29% Params, 24.77 MMACs = 0.84% MACs, 51.09 MFLOPS = 0.42% FLOPs
          (0): Conv2d(6.14 K = 0.27% Params, 24.77 MMACs = 0.84% MACs, 49.55 MFLOPS = 0.42% FLOPs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384 = 0.02% Params, 0 MACs = 0% MACs, 1.55 MFLOPS = 0% FLOPs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          2.11 K = 0.09% Params, 6.97 MMACs = 0.24% MACs, 15.48 MFLOPS = 0.12% FLOPs
          (0): Conv2d(1.73 K = 0.08% Params, 6.97 MMACs = 0.24% MACs, 13.93 MFLOPS = 0.12% FLOPs, 192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
          (1): BatchNorm2d(384 = 0.02% Params, 0 MACs = 0% MACs, 1.55 MFLOPS = 0% FLOPs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(6.14 K = 0.27% Params, 24.77 MMACs = 0.84% MACs, 49.55 MFLOPS = 0.42% FLOPs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64 = 0% Params, 0 MACs = 0% MACs, 258.05 KFLOPS = 0% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): InvertedResidual(
      21.06 K = 0.94% Params, 38.9 MMACs = 1.32% MACs, 79.87 MFLOPS = 0.65% FLOPs
      (conv): Sequential(
        21.06 K = 0.94% Params, 38.9 MMACs = 1.32% MACs, 79.87 MFLOPS = 0.65% FLOPs
        (0): Conv2dNormActivation(
          6.53 K = 0.29% Params, 24.77 MMACs = 0.84% MACs, 51.09 MFLOPS = 0.42% FLOPs
          (0): Conv2d(6.14 K = 0.27% Params, 24.77 MMACs = 0.84% MACs, 49.55 MFLOPS = 0.42% FLOPs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384 = 0.02% Params, 0 MACs = 0% MACs, 1.55 MFLOPS = 0% FLOPs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          2.11 K = 0.09% Params, 1.74 MMACs = 0.06% MACs, 3.87 MFLOPS = 0.03% FLOPs
          (0): Conv2d(1.73 K = 0.08% Params, 1.74 MMACs = 0.06% MACs, 3.48 MFLOPS = 0.03% FLOPs, 192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
          (1): BatchNorm2d(384 = 0.02% Params, 0 MACs = 0% MACs, 387.07 KFLOPS = 0% FLOPs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(12.29 K = 0.55% Params, 12.39 MMACs = 0.42% MACs, 24.77 MFLOPS = 0.21% FLOPs, 192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(128 = 0.01% Params, 0 MACs = 0% MACs, 129.02 KFLOPS = 0% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (8): InvertedResidual(
      54.27 K = 2.42% Params, 53.03 MMACs = 1.8% MACs, 107.74 MFLOPS = 0.89% FLOPs
      (conv): Sequential(
        54.27 K = 2.42% Params, 53.03 MMACs = 1.8% MACs, 107.74 MFLOPS = 0.89% FLOPs
        (0): Conv2dNormActivation(
          25.34 K = 1.13% Params, 24.77 MMACs = 0.84% MACs, 50.32 MFLOPS = 0.42% FLOPs
          (0): Conv2d(24.58 K = 1.1% Params, 24.77 MMACs = 0.84% MACs, 49.55 MFLOPS = 0.42% FLOPs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          4.22 K = 0.19% Params, 3.48 MMACs = 0.12% MACs, 7.74 MFLOPS = 0.06% FLOPs
          (0): Conv2d(3.46 K = 0.15% Params, 3.48 MMACs = 0.12% MACs, 6.97 MFLOPS = 0.06% FLOPs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(24.58 K = 1.1% Params, 24.77 MMACs = 0.84% MACs, 49.55 MFLOPS = 0.42% FLOPs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(128 = 0.01% Params, 0 MACs = 0% MACs, 129.02 KFLOPS = 0% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (9): InvertedResidual(
      54.27 K = 2.42% Params, 53.03 MMACs = 1.8% MACs, 107.74 MFLOPS = 0.89% FLOPs
      (conv): Sequential(
        54.27 K = 2.42% Params, 53.03 MMACs = 1.8% MACs, 107.74 MFLOPS = 0.89% FLOPs
        (0): Conv2dNormActivation(
          25.34 K = 1.13% Params, 24.77 MMACs = 0.84% MACs, 50.32 MFLOPS = 0.42% FLOPs
          (0): Conv2d(24.58 K = 1.1% Params, 24.77 MMACs = 0.84% MACs, 49.55 MFLOPS = 0.42% FLOPs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          4.22 K = 0.19% Params, 3.48 MMACs = 0.12% MACs, 7.74 MFLOPS = 0.06% FLOPs
          (0): Conv2d(3.46 K = 0.15% Params, 3.48 MMACs = 0.12% MACs, 6.97 MFLOPS = 0.06% FLOPs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(24.58 K = 1.1% Params, 24.77 MMACs = 0.84% MACs, 49.55 MFLOPS = 0.42% FLOPs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(128 = 0.01% Params, 0 MACs = 0% MACs, 129.02 KFLOPS = 0% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (10): InvertedResidual(
      54.27 K = 2.42% Params, 53.03 MMACs = 1.8% MACs, 107.74 MFLOPS = 0.89% FLOPs
      (conv): Sequential(
        54.27 K = 2.42% Params, 53.03 MMACs = 1.8% MACs, 107.74 MFLOPS = 0.89% FLOPs
        (0): Conv2dNormActivation(
          25.34 K = 1.13% Params, 24.77 MMACs = 0.84% MACs, 50.32 MFLOPS = 0.42% FLOPs
          (0): Conv2d(24.58 K = 1.1% Params, 24.77 MMACs = 0.84% MACs, 49.55 MFLOPS = 0.42% FLOPs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          4.22 K = 0.19% Params, 3.48 MMACs = 0.12% MACs, 7.74 MFLOPS = 0.06% FLOPs
          (0): Conv2d(3.46 K = 0.15% Params, 3.48 MMACs = 0.12% MACs, 6.97 MFLOPS = 0.06% FLOPs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(24.58 K = 1.1% Params, 24.77 MMACs = 0.84% MACs, 49.55 MFLOPS = 0.42% FLOPs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(128 = 0.01% Params, 0 MACs = 0% MACs, 129.02 KFLOPS = 0% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (11): InvertedResidual(
      66.62 K = 2.97% Params, 65.42 MMACs = 2.22% MACs, 132.57 MFLOPS = 1.1% FLOPs
      (conv): Sequential(
        66.62 K = 2.97% Params, 65.42 MMACs = 2.22% MACs, 132.57 MFLOPS = 1.1% FLOPs
        (0): Conv2dNormActivation(
          25.34 K = 1.13% Params, 24.77 MMACs = 0.84% MACs, 50.32 MFLOPS = 0.42% FLOPs
          (0): Conv2d(24.58 K = 1.1% Params, 24.77 MMACs = 0.84% MACs, 49.55 MFLOPS = 0.42% FLOPs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          4.22 K = 0.19% Params, 3.48 MMACs = 0.12% MACs, 7.74 MFLOPS = 0.06% FLOPs
          (0): Conv2d(3.46 K = 0.15% Params, 3.48 MMACs = 0.12% MACs, 6.97 MFLOPS = 0.06% FLOPs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(768 = 0.03% Params, 0 MACs = 0% MACs, 774.14 KFLOPS = 0% FLOPs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(36.86 K = 1.65% Params, 37.16 MMACs = 1.26% MACs, 74.32 MFLOPS = 0.62% FLOPs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(192 = 0.01% Params, 0 MACs = 0% MACs, 193.54 KFLOPS = 0% FLOPs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (12): InvertedResidual(
      118.27 K = 5.28% Params, 116.7 MMACs = 3.96% MACs, 235.92 MFLOPS = 1.96% FLOPs
      (conv): Sequential(
        118.27 K = 5.28% Params, 116.7 MMACs = 3.96% MACs, 235.92 MFLOPS = 1.96% FLOPs
        (0): Conv2dNormActivation(
          56.45 K = 2.52% Params, 55.74 MMACs = 1.89% MACs, 112.64 MFLOPS = 0.93% FLOPs
          (0): Conv2d(55.3 K = 2.47% Params, 55.74 MMACs = 1.89% MACs, 111.48 MFLOPS = 0.93% FLOPs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1.15 K = 0.05% Params, 0 MACs = 0% MACs, 1.16 MFLOPS = 0% FLOPs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          6.34 K = 0.28% Params, 5.23 MMACs = 0.18% MACs, 11.61 MFLOPS = 0.09% FLOPs
          (0): Conv2d(5.18 K = 0.23% Params, 5.23 MMACs = 0.18% MACs, 10.45 MFLOPS = 0.09% FLOPs, 576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
          (1): BatchNorm2d(1.15 K = 0.05% Params, 0 MACs = 0% MACs, 1.16 MFLOPS = 0% FLOPs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(55.3 K = 2.47% Params, 55.74 MMACs = 1.89% MACs, 111.48 MFLOPS = 0.93% FLOPs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(192 = 0.01% Params, 0 MACs = 0% MACs, 193.54 KFLOPS = 0% FLOPs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): InvertedResidual(
      118.27 K = 5.28% Params, 116.7 MMACs = 3.96% MACs, 235.92 MFLOPS = 1.96% FLOPs
      (conv): Sequential(
        118.27 K = 5.28% Params, 116.7 MMACs = 3.96% MACs, 235.92 MFLOPS = 1.96% FLOPs
        (0): Conv2dNormActivation(
          56.45 K = 2.52% Params, 55.74 MMACs = 1.89% MACs, 112.64 MFLOPS = 0.93% FLOPs
          (0): Conv2d(55.3 K = 2.47% Params, 55.74 MMACs = 1.89% MACs, 111.48 MFLOPS = 0.93% FLOPs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1.15 K = 0.05% Params, 0 MACs = 0% MACs, 1.16 MFLOPS = 0% FLOPs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          6.34 K = 0.28% Params, 5.23 MMACs = 0.18% MACs, 11.61 MFLOPS = 0.09% FLOPs
          (0): Conv2d(5.18 K = 0.23% Params, 5.23 MMACs = 0.18% MACs, 10.45 MFLOPS = 0.09% FLOPs, 576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
          (1): BatchNorm2d(1.15 K = 0.05% Params, 0 MACs = 0% MACs, 1.16 MFLOPS = 0% FLOPs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(55.3 K = 2.47% Params, 55.74 MMACs = 1.89% MACs, 111.48 MFLOPS = 0.93% FLOPs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(192 = 0.01% Params, 0 MACs = 0% MACs, 193.54 KFLOPS = 0% FLOPs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (14): InvertedResidual(
      155.26 K = 6.93% Params, 80.27 MMACs = 2.73% MACs, 162.07 MFLOPS = 1.35% FLOPs
      (conv): Sequential(
        155.26 K = 6.93% Params, 80.27 MMACs = 2.73% MACs, 162.07 MFLOPS = 1.35% FLOPs
        (0): Conv2dNormActivation(
          56.45 K = 2.52% Params, 55.74 MMACs = 1.89% MACs, 112.64 MFLOPS = 0.93% FLOPs
          (0): Conv2d(55.3 K = 2.47% Params, 55.74 MMACs = 1.89% MACs, 111.48 MFLOPS = 0.93% FLOPs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1.15 K = 0.05% Params, 0 MACs = 0% MACs, 1.16 MFLOPS = 0% FLOPs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          6.34 K = 0.28% Params, 1.31 MMACs = 0.04% MACs, 2.9 MFLOPS = 0.02% FLOPs
          (0): Conv2d(5.18 K = 0.23% Params, 1.31 MMACs = 0.04% MACs, 2.61 MFLOPS = 0.02% FLOPs, 576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)
          (1): BatchNorm2d(1.15 K = 0.05% Params, 0 MACs = 0% MACs, 290.3 KFLOPS = 0% FLOPs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(92.16 K = 4.11% Params, 23.22 MMACs = 0.79% MACs, 46.45 MFLOPS = 0.39% FLOPs, 576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(320 = 0.01% Params, 0 MACs = 0% MACs, 80.64 KFLOPS = 0% FLOPs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (15): InvertedResidual(
      320 K = 14.28% Params, 79.59 MMACs = 2.7% MACs, 160.23 MFLOPS = 1.33% FLOPs
      (conv): Sequential(
        320 K = 14.28% Params, 79.59 MMACs = 2.7% MACs, 160.23 MFLOPS = 1.33% FLOPs
        (0): Conv2dNormActivation(
          155.52 K = 6.94% Params, 38.71 MMACs = 1.31% MACs, 77.9 MFLOPS = 0.65% FLOPs
          (0): Conv2d(153.6 K = 6.86% Params, 38.71 MMACs = 1.31% MACs, 77.41 MFLOPS = 0.65% FLOPs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1.92 K = 0.09% Params, 0 MACs = 0% MACs, 483.84 KFLOPS = 0% FLOPs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          10.56 K = 0.47% Params, 2.18 MMACs = 0.07% MACs, 4.84 MFLOPS = 0.04% FLOPs
          (0): Conv2d(8.64 K = 0.39% Params, 2.18 MMACs = 0.07% MACs, 4.35 MFLOPS = 0.04% FLOPs, 960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
          (1): BatchNorm2d(1.92 K = 0.09% Params, 0 MACs = 0% MACs, 483.84 KFLOPS = 0% FLOPs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(153.6 K = 6.86% Params, 38.71 MMACs = 1.31% MACs, 77.41 MFLOPS = 0.65% FLOPs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(320 = 0.01% Params, 0 MACs = 0% MACs, 80.64 KFLOPS = 0% FLOPs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (16): InvertedResidual(
      320 K = 14.28% Params, 79.59 MMACs = 2.7% MACs, 160.23 MFLOPS = 1.33% FLOPs
      (conv): Sequential(
        320 K = 14.28% Params, 79.59 MMACs = 2.7% MACs, 160.23 MFLOPS = 1.33% FLOPs
        (0): Conv2dNormActivation(
          155.52 K = 6.94% Params, 38.71 MMACs = 1.31% MACs, 77.9 MFLOPS = 0.65% FLOPs
          (0): Conv2d(153.6 K = 6.86% Params, 38.71 MMACs = 1.31% MACs, 77.41 MFLOPS = 0.65% FLOPs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1.92 K = 0.09% Params, 0 MACs = 0% MACs, 483.84 KFLOPS = 0% FLOPs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          10.56 K = 0.47% Params, 2.18 MMACs = 0.07% MACs, 4.84 MFLOPS = 0.04% FLOPs
          (0): Conv2d(8.64 K = 0.39% Params, 2.18 MMACs = 0.07% MACs, 4.35 MFLOPS = 0.04% FLOPs, 960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
          (1): BatchNorm2d(1.92 K = 0.09% Params, 0 MACs = 0% MACs, 483.84 KFLOPS = 0% FLOPs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(153.6 K = 6.86% Params, 38.71 MMACs = 1.31% MACs, 77.41 MFLOPS = 0.65% FLOPs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(320 = 0.01% Params, 0 MACs = 0% MACs, 80.64 KFLOPS = 0% FLOPs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (17): InvertedResidual(
      473.92 K = 21.15% Params, 118.3 MMACs = 4.02% MACs, 237.73 MFLOPS = 1.98% FLOPs
      (conv): Sequential(
        473.92 K = 21.15% Params, 118.3 MMACs = 4.02% MACs, 237.73 MFLOPS = 1.98% FLOPs
        (0): Conv2dNormActivation(
          155.52 K = 6.94% Params, 38.71 MMACs = 1.31% MACs, 77.9 MFLOPS = 0.65% FLOPs
          (0): Conv2d(153.6 K = 6.86% Params, 38.71 MMACs = 1.31% MACs, 77.41 MFLOPS = 0.65% FLOPs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1.92 K = 0.09% Params, 0 MACs = 0% MACs, 483.84 KFLOPS = 0% FLOPs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (1): Conv2dNormActivation(
          10.56 K = 0.47% Params, 2.18 MMACs = 0.07% MACs, 4.84 MFLOPS = 0.04% FLOPs
          (0): Conv2d(8.64 K = 0.39% Params, 2.18 MMACs = 0.07% MACs, 4.35 MFLOPS = 0.04% FLOPs, 960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
          (1): BatchNorm2d(1.92 K = 0.09% Params, 0 MACs = 0% MACs, 483.84 KFLOPS = 0% FLOPs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
        )
        (2): Conv2d(307.2 K = 13.71% Params, 77.41 MMACs = 2.63% MACs, 154.83 MFLOPS = 1.3% FLOPs, 960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(640 = 0.03% Params, 0 MACs = 0% MACs, 161.28 KFLOPS = 0% FLOPs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (18): Conv2dNormActivation(
      103.04 K = 4.6% Params, 25.8 MMACs = 0.88% MACs, 51.77 MFLOPS = 0.43% FLOPs
      (0): Conv2d(102.4 K = 4.57% Params, 25.8 MMACs = 0.88% MACs, 51.61 MFLOPS = 0.43% FLOPs, 320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(640 = 0.03% Params, 0 MACs = 0% MACs, 161.28 KFLOPS = 0% FLOPs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, inplace=True)
    )
  )
  (deconv_layers): Sequential(
    256.24 K = 11.44% Params, 361.27 MMACs = 12.27% MACs, 727.61 MFLOPS = 6.05% FLOPs
    (0): ConvTranspose2d(204.8 K = 9.14% Params, 103.22 MMACs = 3.51% MACs, 206.44 MFLOPS = 1.73% FLOPs, 320, 40, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(80 = 0% Params, 0 MACs = 0% MACs, 161.28 KFLOPS = 0% FLOPs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 80.64 KFLOPS = 0% FLOPs, inplace=True)
    (3): ConvTranspose2d(25.6 K = 1.14% Params, 51.61 MMACs = 1.75% MACs, 103.22 MFLOPS = 0.86% FLOPs, 40, 40, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(80 = 0% Params, 0 MACs = 0% MACs, 645.12 KFLOPS = 0% FLOPs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 322.56 KFLOPS = 0% FLOPs, inplace=True)
    (6): ConvTranspose2d(25.6 K = 1.14% Params, 206.44 MMACs = 7.01% MACs, 412.88 MFLOPS = 3.46% FLOPs, 40, 40, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(80 = 0% Params, 0 MACs = 0% MACs, 2.58 MFLOPS = 0% FLOPs, 40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.29 MFLOPS = 0% FLOPs, inplace=True)
  )
  (hm): Sequential(
    23.17 K = 1.03% Params, 372.62 MMACs = 12.66% MACs, 747.32 MFLOPS = 6.24% FLOPs
    (0): Conv2d(23.1 K = 1.03% Params, 371.59 MMACs = 12.62% MACs, 744.21 MFLOPS = 6.23% FLOPs, 40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.03 MFLOPS = 0% FLOPs, inplace=True)
    (2): Conv2d(65 = 0% Params, 1.03 MMACs = 0.04% MACs, 2.08 MFLOPS = 0.02% FLOPs, 64, 1, kernel_size=(1, 1), stride=(1, 1))
  )
  (reg): Sequential(
    23.23 K = 1.04% Params, 373.65 MMACs = 12.69% MACs, 749.4 MFLOPS = 6.26% FLOPs
    (0): Conv2d(23.1 K = 1.03% Params, 371.59 MMACs = 12.62% MACs, 744.21 MFLOPS = 6.23% FLOPs, 40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.03 MFLOPS = 0% FLOPs, inplace=True)
    (2): Conv2d(130 = 0.01% Params, 2.06 MMACs = 0.07% MACs, 4.16 MFLOPS = 0.03% FLOPs, 64, 2, kernel_size=(1, 1), stride=(1, 1))
  )
  (face_hm): Sequential(
    23.23 K = 1.04% Params, 373.65 MMACs = 12.69% MACs, 749.4 MFLOPS = 6.26% FLOPs
    (0): Conv2d(23.1 K = 1.03% Params, 371.59 MMACs = 12.62% MACs, 744.21 MFLOPS = 6.23% FLOPs, 40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.03 MFLOPS = 0% FLOPs, inplace=True)
    (2): Conv2d(130 = 0.01% Params, 2.06 MMACs = 0.07% MACs, 4.16 MFLOPS = 0.03% FLOPs, 64, 2, kernel_size=(1, 1), stride=(1, 1))
  )
)
---------------------------------------------------------------------------------------------------
flops  5.97 GFLOPS
params 2.24 M